{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medalidia/apprentissage_git/blob/main/projet_polarite_avis_clients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2354b328",
      "metadata": {
        "id": "2354b328"
      },
      "source": [
        "\n",
        "# Projet NLP – Classification de la polarité des avis clients\n",
        "**Auteur : Mohamed Ali Dia**  \n",
        "**Date : 12 Juillet 2025**  \n",
        "\n",
        "Ce projet a pour objectif de développer un système automatique permettant de classifier un avis client en ligne comme **positif** ou **négatif**, en utilisant un jeu de données d’avis en français.  \n",
        "Nous allons passer par les étapes suivantes :\n",
        "\n",
        "- Prétraitement des textes (nettoyage, lemmatisation)\n",
        "- Analyse exploratoire\n",
        "- Vectorisation des textes (TF-IDF)\n",
        "- Entraînement de plusieurs modèles de classification\n",
        "- Évaluation comparative\n",
        "- Sauvegarde des modèles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b3d8d7",
      "metadata": {
        "id": "78b3d8d7"
      },
      "source": [
        "## 1. Importation des bibliothèques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6be75187",
      "metadata": {
        "id": "6be75187"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd                   # manipulation de données en DataFrame\n",
        "import numpy as np                    # calculs numériques\n",
        "import matplotlib.pyplot as plt       # visualisation graphique\n",
        "import seaborn as sns                 # visualisation avancée basée sur matplotlib\n",
        "import re                             # expressions régulières pour nettoyage texte\n",
        "import string                         # manipulation de chaînes (ponctuation)\n",
        "import nltk                           # traitement de texte (stopwords)\n",
        "import joblib                         # sauvegarde et chargement de modèles\n",
        "import spacy                          # NLP : lemmatisation, tokenisation avancée\n",
        "from wordcloud import WordCloud       # génération de nuage de mots\n",
        "from collections import Counter       # compter la fréquence des mots\n",
        "import itertools                      # opérations sur itérables\n",
        "from nltk.corpus import stopwords     # liste des mots vides (stopwords)\n",
        "\n",
        "from sklearn.model_selection import train_test_split                           # séparation train/test\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer   # vectorisation TF-IDF et compte\n",
        "from sklearn.linear_model import LogisticRegression                            # Logistic Regression\n",
        "from sklearn.svm import LinearSVC                                              # SVM linéaire\n",
        "from sklearn.ensemble import RandomForestClassifier                            # Random Forest\n",
        "from sklearn.pipeline import Pipeline                                          # pipeline de traitement\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37facfe",
      "metadata": {
        "id": "d37facfe"
      },
      "source": [
        "## 2. Préparation des outils linguistiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "455fcec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455fcec6",
        "outputId": "4476b70a-a2f1-4825-adbd-bbeaf456424d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "# Téléchargement des stopwords français si non déjà présents\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger la liste des mots vides en français\n",
        "stop_words = set(stopwords.words('french'))"
      ],
      "metadata": {
        "id": "n4CO0AKlU3Zu"
      },
      "id": "n4CO0AKlU3Zu",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du modèle SpaCy français avec gestion d’erreur\n",
        "import subprocess\n",
        "try:\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "except:\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"])\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")"
      ],
      "metadata": {
        "id": "0QiNS7u6Ut0O"
      },
      "id": "0QiNS7u6Ut0O",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "20fdc828",
      "metadata": {
        "id": "20fdc828"
      },
      "source": [
        "## 3. Chargement du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f6336d73",
      "metadata": {
        "id": "f6336d73"
      },
      "outputs": [],
      "source": [
        "# Définition des chemins vers les splits train, validation, test\n",
        "splits = {\n",
        "    'train': 'allocine/train-00000-of-00001.parquet',\n",
        "    'validation': 'allocine/validation-00000-of-00001.parquet',\n",
        "    'test': 'allocine/test-00000-of-00001.parquet'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du fichier parquet d'entraînement depuis HuggingFace datasets\n",
        "df = pd.read_parquet(\"hf://datasets/tblard/allocine/\" + splits[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqOzP-i9VHng",
        "outputId": "ed43ab65-45cc-497a-e6f6-31ed3d342dd0"
      },
      "id": "BqOzP-i9VHng",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pour accélérer le traitement, on réduit à un échantillon de 10 000 exemples pour limiter le temps d'exécution\n",
        "df = df.sample(10000, random_state=42)\n",
        "\n",
        "# Ne garder que les colonnes utiles 'review'(texte) et 'label' (polarité)\n",
        "df = df[['review', 'label']]"
      ],
      "metadata": {
        "id": "kW3b0IocVYTu"
      },
      "id": "kW3b0IocVYTu",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des premières lignes du DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y31FDu3VlLm",
        "outputId": "46963111-e2c1-44d0-d91f-81b1c6a9155e"
      },
      "id": "6Y31FDu3VlLm",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   review  label\n",
            "120476  Un excellent thriller d'action où les scènes d...      1\n",
            "32693   Si le scénariste, qui aurait pu faire un minim...      0\n",
            "79958   Référence dans la filmographie de Bogart, \"Le ...      0\n",
            "76366   Un bon scénario, un bon film, une histoire lou...      1\n",
            "82343   Un scenario vide et une mise en scene trés sop...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "857890a5",
      "metadata": {
        "id": "857890a5"
      },
      "source": [
        "## 4. Nettoyage et lemmatisation des textes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a089ef27",
      "metadata": {
        "id": "a089ef27"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "    Cette fonction nettoie un texte brut :\n",
        "    - Passage en minuscules\n",
        "    - Suppression des chiffres\n",
        "    - Suppression de la ponctuation\n",
        "    - Lemmatisation avec SpaCy\n",
        "    - Suppression des stopwords, des tokens non alphabétiques et très courts (< 3 caractères)\n",
        "  \"\"\"\n",
        "def clean_and_lemmatize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Analyse SpaCy\n",
        "    doc = nlp(text)\n",
        "    tokens = [\n",
        "        token.lemma_ for token in doc if token.lemma_.lower() not in stop_words and token.is_alpha and len(token) > 2\n",
        "    ]\n",
        "    return \" \".join(tokens)   # reconstruire phrase nettoyée et lemmatisée\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Application de la fonction à la colonne 'review' pour créer une nouvelle colonne 'clean_review'\n",
        "df['clean_review'] = df['review'].apply(clean_and_lemmatize)"
      ],
      "metadata": {
        "id": "_Pxgs9odW4dU"
      },
      "id": "_Pxgs9odW4dU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher un aperçu des textes originaux et nettoyés\n",
        "df[['review', 'clean_review']].head()"
      ],
      "metadata": {
        "id": "bRB8JeIsW8w4"
      },
      "id": "bRB8JeIsW8w4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8f559b84",
      "metadata": {
        "id": "8f559b84"
      },
      "source": [
        "## 5. Exploration des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa035230",
      "metadata": {
        "id": "fa035230"
      },
      "outputs": [],
      "source": [
        "# Afficher la distribution des classes (0 = négatif, 1 = positif)\n",
        "print(df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation graphique de la répartition des classes\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title(\"Distribution des avis\")\n",
        "plt.xlabel(\"Label (0 = négatif, 1 = positif)\")\n",
        "plt.ylabel(\"Nombre d'exemples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XPWB2cDFXNaC"
      },
      "id": "XPWB2cDFXNaC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1e5ca3a0",
      "metadata": {
        "id": "1e5ca3a0"
      },
      "source": [
        "## 6. Visualisation des mots les plus fréquents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee7e063",
      "metadata": {
        "id": "0ee7e063"
      },
      "outputs": [],
      "source": [
        "# Extraction de tous les mots issus de la colonne nettoyée\n",
        "all_words = list(itertools.chain(*df['clean_review'].str.split()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compter la fréquence des 20 mots les plus fréquents\n",
        "word_freq = Counter(all_words).most_common(20)\n",
        "words, counts = zip(*word_freq)"
      ],
      "metadata": {
        "id": "y_PRvqFgXc4H"
      },
      "id": "y_PRvqFgXc4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage sous forme de barplot\n",
        "sns.barplot(x=counts, y=words)\n",
        "plt.title(\"20 mots les plus fréquents\")\n",
        "plt.xlabel(\"Fréquence\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zJYlTuCdXiw_"
      },
      "id": "zJYlTuCdXiw_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuage de mots basé sur l'ensemble des mots\n",
        "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(all_words))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nuage de mots\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cw6MN-rLXofl"
      },
      "id": "Cw6MN-rLXofl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6c940217",
      "metadata": {
        "id": "6c940217"
      },
      "source": [
        "## 7. Vectorisation des textes avec TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296b339b",
      "metadata": {
        "id": "296b339b"
      },
      "outputs": [],
      "source": [
        "# On initialise le vectoriseur TF-IDF en limitant à 5000 features et en incluant\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul de la matrice TF-IDF sur les textes nettoyés\n",
        "X = vectorizer.fit_transform(df['clean_review'])"
      ],
      "metadata": {
        "id": "jcqn2asDX3q1"
      },
      "id": "jcqn2asDX3q1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupération des labels\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "U8xcfDICX8A0"
      },
      "id": "U8xcfDICX8A0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3e04e658",
      "metadata": {
        "id": "3e04e658"
      },
      "source": [
        "## 8. Séparation des données d'entraînement et de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15b12d5f",
      "metadata": {
        "id": "15b12d5f"
      },
      "outputs": [],
      "source": [
        "# 20% des données sont réservées au test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05770da",
      "metadata": {
        "id": "a05770da"
      },
      "source": [
        "## 9. Entraînement des modèles de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4b7fea",
      "metadata": {
        "id": "3d4b7fea"
      },
      "outputs": [],
      "source": [
        "# Régression logistique\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM linéaire\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "_v9VMFpKYWcX"
      },
      "id": "_v9VMFpKYWcX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "53ZskssLYWJK"
      },
      "id": "53ZskssLYWJK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9752c68f",
      "metadata": {
        "id": "9752c68f"
      },
      "source": [
        "## 10. Évaluation des modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507145d1",
      "metadata": {
        "id": "507145d1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Cette fonction permet d'afficher la matrice de confusion, le rapport de classification et la précision globale.\n",
        "    Elle permet d'affiche aussi graphiquement la matrice de confusion.\n",
        "    \"\"\"\n",
        "def eval_model(name, y_true, y_pred):\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=[\"Négatif\", \"Positif\"])\n",
        "    plt.title(f\"{name} - Matrice de confusion\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation des modèles\n",
        "eval_model(\"Régression Logistique\", y_test, y_pred_lr)\n",
        "eval_model(\"SVM Linéaire\", y_test, y_pred_svm)\n",
        "eval_model(\"Random Forest\", y_test, y_pred_rf)"
      ],
      "metadata": {
        "id": "X4DHBuHtYvNM"
      },
      "id": "X4DHBuHtYvNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bcb06d2a",
      "metadata": {
        "id": "bcb06d2a"
      },
      "source": [
        "### 🔍 F1-score pondéré (complément d'évaluation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le calcul des F1-score pondérés est précieux pour mesurer la performance globale sur les classes déséquilibrées"
      ],
      "metadata": {
        "id": "REUqhddFZTkL"
      },
      "id": "REUqhddFZTkL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219d0259",
      "metadata": {
        "id": "219d0259"
      },
      "outputs": [],
      "source": [
        "# Calcul des F1-score pondérés\n",
        "print(\"F1-score pondéré - Logistic Regression :\", f1_score(y_test, y_pred_lr, average=\"weighted\"))\n",
        "print(\"F1-score pondéré - SVM :\", f1_score(y_test, y_pred_svm, average=\"weighted\"))\n",
        "print(\"F1-score pondéré - Random Forest :\", f1_score(y_test, y_pred_rf, average=\"weighted\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c763887b",
      "metadata": {
        "id": "c763887b"
      },
      "source": [
        "## 11. Comparaison des performances des modèles (accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcf5151",
      "metadata": {
        "id": "4bcf5151"
      },
      "outputs": [],
      "source": [
        "\n",
        "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
        "accuracies = [\n",
        "    accuracy_score(y_test, y_pred_lr),\n",
        "    accuracy_score(y_test, y_pred_svm),\n",
        "    accuracy_score(y_test, y_pred_rf)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphique de comparaison\n",
        "sns.barplot(x=models, y=accuracies)\n",
        "plt.title(\"Comparaison des précisions\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w9IWYbkWZvXG"
      },
      "id": "w9IWYbkWZvXG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "968f735f",
      "metadata": {
        "id": "968f735f"
      },
      "source": [
        "## 12. Échantillon de prédictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemple de prédictions sur un petit échantillon pour voir les résultats concrets"
      ],
      "metadata": {
        "id": "4YYV4GSSZ4kv"
      },
      "id": "4YYV4GSSZ4kv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f150a2",
      "metadata": {
        "id": "c0f150a2"
      },
      "outputs": [],
      "source": [
        "# Test sur un échantillon (y_test)\n",
        "indices = y_test.iloc[:5].index\n",
        "sample_preds = pd.DataFrame({\n",
        "    \"Review\": df.loc[indices, 'review'].values,\n",
        "    \"Label réel\": y_test.loc[indices].values,\n",
        "    \"Prédiction LR\": y_pred_lr[:5],\n",
        "    \"Prédiction SVM\": y_pred_svm[:5],\n",
        "    \"Prédiction RF\": y_pred_rf[:5]\n",
        "})\n",
        "sample_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497d8ca1",
      "metadata": {
        "id": "497d8ca1"
      },
      "source": [
        "## 13. Sauvegarde des modèles entraînés pour réutilisation future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112610cd",
      "metadata": {
        "id": "112610cd"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")    # vectoriseur TF-IDF\n",
        "joblib.dump(lr_model, \"logistic_model.pkl\")        # modèle Logistic Regression\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")            # modèle SVM\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")   # modèle Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'un pipeline complet avec vectorisation + modèle LR pour simplifier la prédiction ultérieure\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "pipeline_lr.fit(df['clean_review'], df['label'])\n",
        "joblib.dump(pipeline_lr, \"pipeline_logistic.pkl\")\n",
        "\n",
        "print(\"Tous les modèles ont été sauvegardés avec succès.\")\n"
      ],
      "metadata": {
        "id": "cbXzjFCRaZ2m"
      },
      "id": "cbXzjFCRaZ2m",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}