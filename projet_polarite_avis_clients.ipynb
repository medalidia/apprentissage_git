{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2354b328",
      "metadata": {
        "id": "2354b328"
      },
      "source": [
        "\n",
        "# Projet NLP ‚Äì Classification de la polarit√© des avis clients\n",
        "**Auteur : Mohamed Ali Dia**  \n",
        "**Date : Juillet 2025**  \n",
        "\n",
        "Ce projet a pour objectif de d√©velopper un syst√®me automatique permettant de classifier un avis client en ligne comme **positif** ou **n√©gatif**, en utilisant un jeu de donn√©es d‚Äôavis en fran√ßais.  \n",
        "Nous allons passer par les √©tapes suivantes :\n",
        "\n",
        "- Pr√©traitement des textes (nettoyage, lemmatisation)\n",
        "- Analyse exploratoire\n",
        "- Vectorisation des textes (TF-IDF)\n",
        "- Entra√Ænement de plusieurs mod√®les de classification\n",
        "- √âvaluation comparative\n",
        "- Sauvegarde des mod√®les\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b3d8d7",
      "metadata": {
        "id": "78b3d8d7"
      },
      "source": [
        "## 1. Importation des biblioth√®ques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6be75187",
      "metadata": {
        "id": "6be75187"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import joblib\n",
        "import spacy\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37facfe",
      "metadata": {
        "id": "d37facfe"
      },
      "source": [
        "## 2. Pr√©paration des outils linguistiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "455fcec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455fcec6",
        "outputId": "7ccec600-1862-40f8-f194-fa9cf79502fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('french'))\n",
        "\n",
        "# Chargement du mod√®le SpaCy fran√ßais avec gestion d‚Äôerreur\n",
        "import subprocess\n",
        "try:\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "except:\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"])\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20fdc828",
      "metadata": {
        "id": "20fdc828"
      },
      "source": [
        "## 3. Chargement du jeu de donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6336d73",
      "metadata": {
        "id": "f6336d73"
      },
      "outputs": [],
      "source": [
        "splits = {'train': 'allocine/train-00000-of-00001.parquet', 'validation': 'allocine/validation-00000-of-00001.parquet', 'test': 'allocine/test-00000-of-00001.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/tblard/allocine/\" + splits[\"train\"])\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# R√©duire √† un √©chantillon pour limiter le temps d'ex√©cution\n",
        "df = df.sample(10000, random_state=42)\n",
        "\n",
        "# Garder uniquement les colonnes utiles\n",
        "df = df[['review', 'label']]\n",
        "\n",
        "# Affichage des premi√®res lignes\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "857890a5",
      "metadata": {
        "id": "857890a5"
      },
      "source": [
        "## 4. Nettoyage et lemmatisation des textes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a089ef27",
      "metadata": {
        "id": "a089ef27"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_and_lemmatize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc\n",
        "              if token.lemma_.lower() not in stop_words and token.is_alpha and len(token) > 2]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['clean_review'] = df['review'].apply(clean_and_lemmatize)\n",
        "df[['review', 'clean_review']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f559b84",
      "metadata": {
        "id": "8f559b84"
      },
      "source": [
        "## 5. Exploration des donn√©es (r√©partition des classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa035230",
      "metadata": {
        "id": "fa035230"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title(\"Distribution des avis\")\n",
        "plt.xlabel(\"Label (0 = n√©gatif, 1 = positif)\")\n",
        "plt.ylabel(\"Nombre d'exemples\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5ca3a0",
      "metadata": {
        "id": "1e5ca3a0"
      },
      "source": [
        "## 6. Visualisation des mots les plus fr√©quents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee7e063",
      "metadata": {
        "id": "0ee7e063"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_words = list(itertools.chain(*df['clean_review'].str.split()))\n",
        "word_freq = Counter(all_words).most_common(20)\n",
        "words, counts = zip(*word_freq)\n",
        "\n",
        "sns.barplot(x=counts, y=words)\n",
        "plt.title(\"20 mots les plus fr√©quents\")\n",
        "plt.xlabel(\"Fr√©quence\")\n",
        "plt.show()\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(all_words))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nuage de mots\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c940217",
      "metadata": {
        "id": "6c940217"
      },
      "source": [
        "## 7. Vectorisation des textes (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296b339b",
      "metadata": {
        "id": "296b339b"
      },
      "outputs": [],
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X = vectorizer.fit_transform(df['clean_review'])\n",
        "y = df['label']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e04e658",
      "metadata": {
        "id": "3e04e658"
      },
      "source": [
        "## 8. S√©paration des donn√©es d'entra√Ænement et de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15b12d5f",
      "metadata": {
        "id": "15b12d5f"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05770da",
      "metadata": {
        "id": "a05770da"
      },
      "source": [
        "## 9. Entra√Ænement des mod√®les de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4b7fea",
      "metadata": {
        "id": "3d4b7fea"
      },
      "outputs": [],
      "source": [
        "\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9752c68f",
      "metadata": {
        "id": "9752c68f"
      },
      "source": [
        "## 10. √âvaluation des mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507145d1",
      "metadata": {
        "id": "507145d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def eval_model(name, y_true, y_pred):\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=[\"N√©gatif\", \"Positif\"])\n",
        "    plt.title(f\"{name} - Matrice de confusion\")\n",
        "    plt.show()\n",
        "\n",
        "eval_model(\"R√©gression Logistique\", y_test, y_pred_lr)\n",
        "eval_model(\"SVM Lin√©aire\", y_test, y_pred_svm)\n",
        "eval_model(\"Random Forest\", y_test, y_pred_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb06d2a",
      "metadata": {
        "id": "bcb06d2a"
      },
      "source": [
        "### üîç F1-score pond√©r√© (compl√©ment d'√©valuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219d0259",
      "metadata": {
        "id": "219d0259"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"F1-score pond√©r√© - Logistic Regression :\", f1_score(y_test, y_pred_lr, average=\"weighted\"))\n",
        "print(\"F1-score pond√©r√© - SVM :\", f1_score(y_test, y_pred_svm, average=\"weighted\"))\n",
        "print(\"F1-score pond√©r√© - Random Forest :\", f1_score(y_test, y_pred_rf, average=\"weighted\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c763887b",
      "metadata": {
        "id": "c763887b"
      },
      "source": [
        "## 11. Comparaison des performances des mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcf5151",
      "metadata": {
        "id": "4bcf5151"
      },
      "outputs": [],
      "source": [
        "\n",
        "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
        "accuracies = [\n",
        "    accuracy_score(y_test, y_pred_lr),\n",
        "    accuracy_score(y_test, y_pred_svm),\n",
        "    accuracy_score(y_test, y_pred_rf)\n",
        "]\n",
        "\n",
        "sns.barplot(x=models, y=accuracies)\n",
        "plt.title(\"Comparaison des pr√©cisions\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968f735f",
      "metadata": {
        "id": "968f735f"
      },
      "source": [
        "## 12. √âchantillon de pr√©dictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f150a2",
      "metadata": {
        "id": "c0f150a2"
      },
      "outputs": [],
      "source": [
        "\n",
        "indices = y_test.iloc[:5].index\n",
        "sample_preds = pd.DataFrame({\n",
        "    \"Review\": df.loc[indices, 'review'].values,\n",
        "    \"Label r√©el\": y_test.loc[indices].values,\n",
        "    \"Pr√©diction LR\": y_pred_lr[:5],\n",
        "    \"Pr√©diction SVM\": y_pred_svm[:5],\n",
        "    \"Pr√©diction RF\": y_pred_rf[:5]\n",
        "})\n",
        "sample_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497d8ca1",
      "metadata": {
        "id": "497d8ca1"
      },
      "source": [
        "## 13. Sauvegarde des mod√®les entra√Æn√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112610cd",
      "metadata": {
        "id": "112610cd"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "joblib.dump(lr_model, \"logistic_model.pkl\")\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
        "\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "pipeline_lr.fit(df['clean_review'], df['label'])\n",
        "joblib.dump(pipeline_lr, \"pipeline_logistic.pkl\")\n",
        "\n",
        "print(\"Tous les mod√®les ont √©t√© sauvegard√©s avec succ√®s.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65b1559",
      "metadata": {
        "id": "b65b1559"
      },
      "source": [
        "\n",
        "## 14. Conclusion et perspectives\n",
        "\n",
        "### ‚úÖ R√©sum√©\n",
        "Le syst√®me de classification automatique des avis clients permet d'obtenir de tr√®s bonnes performances, notamment avec la **r√©gression logistique** et le **SVM** qui affichent des scores de pr√©cision √©lev√©s.  \n",
        "Le pr√©traitement des textes (lemmatisation, nettoyage) et l'utilisation de la vectorisation **TF-IDF** se sont r√©v√©l√©s efficaces sur ce jeu de donn√©es.\n",
        "\n",
        "### üöÄ Pistes d'am√©lioration possibles\n",
        "Voici quelques am√©liorations pour renforcer ce syst√®me :\n",
        "- **Utiliser des embeddings s√©mantiques** comme FastText ou BERT pour capturer davantage le sens des mots.\n",
        "- **Optimiser les hyperparam√®tres** via `GridSearchCV` ou `RandomizedSearchCV`.\n",
        "- **G√©rer le d√©s√©quilibre des classes** avec une pond√©ration (`class_weight`) ou de la sur√©chantillonnage (SMOTE).\n",
        "- **Explicabilit√© des mod√®les** avec SHAP ou LIME pour mieux comprendre les pr√©dictions.\n",
        "- **Cr√©er une API Flask** ou une interface simple pour tester des avis en temps r√©el.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}