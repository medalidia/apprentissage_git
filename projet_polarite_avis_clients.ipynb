{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2354b328",
      "metadata": {
        "id": "2354b328"
      },
      "source": [
        "\n",
        "# Projet NLP – Classification de la polarité des avis clients\n",
        "**Auteur : Mohamed Ali Dia**  \n",
        "**Date : Juillet 2025**  \n",
        "\n",
        "Ce projet a pour objectif de développer un système automatique permettant de classifier un avis client en ligne comme **positif** ou **négatif**, en utilisant un jeu de données d’avis en français.  \n",
        "Nous allons passer par les étapes suivantes :\n",
        "\n",
        "- Prétraitement des textes (nettoyage, lemmatisation)\n",
        "- Analyse exploratoire\n",
        "- Vectorisation des textes (TF-IDF)\n",
        "- Entraînement de plusieurs modèles de classification\n",
        "- Évaluation comparative\n",
        "- Sauvegarde des modèles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b3d8d7",
      "metadata": {
        "id": "78b3d8d7"
      },
      "source": [
        "## 1. Importation des bibliothèques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6be75187",
      "metadata": {
        "id": "6be75187"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import joblib\n",
        "import spacy\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37facfe",
      "metadata": {
        "id": "d37facfe"
      },
      "source": [
        "## 2. Préparation des outils linguistiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "455fcec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455fcec6",
        "outputId": "7ccec600-1862-40f8-f194-fa9cf79502fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('french'))\n",
        "\n",
        "# Chargement du modèle SpaCy français avec gestion d’erreur\n",
        "import subprocess\n",
        "try:\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "except:\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"])\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20fdc828",
      "metadata": {
        "id": "20fdc828"
      },
      "source": [
        "## 3. Chargement du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6336d73",
      "metadata": {
        "id": "f6336d73"
      },
      "outputs": [],
      "source": [
        "splits = {'train': 'allocine/train-00000-of-00001.parquet', 'validation': 'allocine/validation-00000-of-00001.parquet', 'test': 'allocine/test-00000-of-00001.parquet'}\n",
        "df = pd.read_parquet(\"hf://datasets/tblard/allocine/\" + splits[\"train\"])\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "# Réduire à un échantillon pour limiter le temps d'exécution\n",
        "df = df.sample(10000, random_state=42)\n",
        "\n",
        "# Garder uniquement les colonnes utiles\n",
        "df = df[['review', 'label']]\n",
        "\n",
        "# Affichage des premières lignes\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "857890a5",
      "metadata": {
        "id": "857890a5"
      },
      "source": [
        "## 4. Nettoyage et lemmatisation des textes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a089ef27",
      "metadata": {
        "id": "a089ef27"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_and_lemmatize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc\n",
        "              if token.lemma_.lower() not in stop_words and token.is_alpha and len(token) > 2]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['clean_review'] = df['review'].apply(clean_and_lemmatize)\n",
        "df[['review', 'clean_review']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f559b84",
      "metadata": {
        "id": "8f559b84"
      },
      "source": [
        "## 5. Exploration des données (répartition des classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa035230",
      "metadata": {
        "id": "fa035230"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title(\"Distribution des avis\")\n",
        "plt.xlabel(\"Label (0 = négatif, 1 = positif)\")\n",
        "plt.ylabel(\"Nombre d'exemples\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5ca3a0",
      "metadata": {
        "id": "1e5ca3a0"
      },
      "source": [
        "## 6. Visualisation des mots les plus fréquents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee7e063",
      "metadata": {
        "id": "0ee7e063"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_words = list(itertools.chain(*df['clean_review'].str.split()))\n",
        "word_freq = Counter(all_words).most_common(20)\n",
        "words, counts = zip(*word_freq)\n",
        "\n",
        "sns.barplot(x=counts, y=words)\n",
        "plt.title(\"20 mots les plus fréquents\")\n",
        "plt.xlabel(\"Fréquence\")\n",
        "plt.show()\n",
        "\n",
        "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(all_words))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nuage de mots\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c940217",
      "metadata": {
        "id": "6c940217"
      },
      "source": [
        "## 7. Vectorisation des textes (TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296b339b",
      "metadata": {
        "id": "296b339b"
      },
      "outputs": [],
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
        "X = vectorizer.fit_transform(df['clean_review'])\n",
        "y = df['label']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e04e658",
      "metadata": {
        "id": "3e04e658"
      },
      "source": [
        "## 8. Séparation des données d'entraînement et de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15b12d5f",
      "metadata": {
        "id": "15b12d5f"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05770da",
      "metadata": {
        "id": "a05770da"
      },
      "source": [
        "## 9. Entraînement des modèles de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4b7fea",
      "metadata": {
        "id": "3d4b7fea"
      },
      "outputs": [],
      "source": [
        "\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9752c68f",
      "metadata": {
        "id": "9752c68f"
      },
      "source": [
        "## 10. Évaluation des modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507145d1",
      "metadata": {
        "id": "507145d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def eval_model(name, y_true, y_pred):\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=[\"Négatif\", \"Positif\"])\n",
        "    plt.title(f\"{name} - Matrice de confusion\")\n",
        "    plt.show()\n",
        "\n",
        "eval_model(\"Régression Logistique\", y_test, y_pred_lr)\n",
        "eval_model(\"SVM Linéaire\", y_test, y_pred_svm)\n",
        "eval_model(\"Random Forest\", y_test, y_pred_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb06d2a",
      "metadata": {
        "id": "bcb06d2a"
      },
      "source": [
        "### 🔍 F1-score pondéré (complément d'évaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219d0259",
      "metadata": {
        "id": "219d0259"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"F1-score pondéré - Logistic Regression :\", f1_score(y_test, y_pred_lr, average=\"weighted\"))\n",
        "print(\"F1-score pondéré - SVM :\", f1_score(y_test, y_pred_svm, average=\"weighted\"))\n",
        "print(\"F1-score pondéré - Random Forest :\", f1_score(y_test, y_pred_rf, average=\"weighted\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c763887b",
      "metadata": {
        "id": "c763887b"
      },
      "source": [
        "## 11. Comparaison des performances des modèles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcf5151",
      "metadata": {
        "id": "4bcf5151"
      },
      "outputs": [],
      "source": [
        "\n",
        "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
        "accuracies = [\n",
        "    accuracy_score(y_test, y_pred_lr),\n",
        "    accuracy_score(y_test, y_pred_svm),\n",
        "    accuracy_score(y_test, y_pred_rf)\n",
        "]\n",
        "\n",
        "sns.barplot(x=models, y=accuracies)\n",
        "plt.title(\"Comparaison des précisions\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968f735f",
      "metadata": {
        "id": "968f735f"
      },
      "source": [
        "## 12. Échantillon de prédictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f150a2",
      "metadata": {
        "id": "c0f150a2"
      },
      "outputs": [],
      "source": [
        "\n",
        "indices = y_test.iloc[:5].index\n",
        "sample_preds = pd.DataFrame({\n",
        "    \"Review\": df.loc[indices, 'review'].values,\n",
        "    \"Label réel\": y_test.loc[indices].values,\n",
        "    \"Prédiction LR\": y_pred_lr[:5],\n",
        "    \"Prédiction SVM\": y_pred_svm[:5],\n",
        "    \"Prédiction RF\": y_pred_rf[:5]\n",
        "})\n",
        "sample_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497d8ca1",
      "metadata": {
        "id": "497d8ca1"
      },
      "source": [
        "## 13. Sauvegarde des modèles entraînés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112610cd",
      "metadata": {
        "id": "112610cd"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "joblib.dump(lr_model, \"logistic_model.pkl\")\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
        "\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "pipeline_lr.fit(df['clean_review'], df['label'])\n",
        "joblib.dump(pipeline_lr, \"pipeline_logistic.pkl\")\n",
        "\n",
        "print(\"Tous les modèles ont été sauvegardés avec succès.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65b1559",
      "metadata": {
        "id": "b65b1559"
      },
      "source": [
        "\n",
        "## 14. Conclusion et perspectives\n",
        "\n",
        "### ✅ Résumé\n",
        "Le système de classification automatique des avis clients permet d'obtenir de très bonnes performances, notamment avec la **régression logistique** et le **SVM** qui affichent des scores de précision élevés.  \n",
        "Le prétraitement des textes (lemmatisation, nettoyage) et l'utilisation de la vectorisation **TF-IDF** se sont révélés efficaces sur ce jeu de données.\n",
        "\n",
        "### 🚀 Pistes d'amélioration possibles\n",
        "Voici quelques améliorations pour renforcer ce système :\n",
        "- **Utiliser des embeddings sémantiques** comme FastText ou BERT pour capturer davantage le sens des mots.\n",
        "- **Optimiser les hyperparamètres** via `GridSearchCV` ou `RandomizedSearchCV`.\n",
        "- **Gérer le déséquilibre des classes** avec une pondération (`class_weight`) ou de la suréchantillonnage (SMOTE).\n",
        "- **Explicabilité des modèles** avec SHAP ou LIME pour mieux comprendre les prédictions.\n",
        "- **Créer une API Flask** ou une interface simple pour tester des avis en temps réel.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}