{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/medalidia/apprentissage_git/blob/main/projet_polarite_avis_clients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2354b328",
      "metadata": {
        "id": "2354b328"
      },
      "source": [
        "\n",
        "# Projet NLP ‚Äì Classification de la polarit√© des avis clients\n",
        "**Auteur : Mohamed Ali Dia**  \n",
        "**Date : 12 Juillet 2025**  \n",
        "\n",
        "Ce projet a pour objectif de d√©velopper un syst√®me automatique permettant de classifier un avis client en ligne comme **positif** ou **n√©gatif**, en utilisant un jeu de donn√©es d‚Äôavis en fran√ßais.  \n",
        "Nous allons passer par les √©tapes suivantes :\n",
        "\n",
        "- Pr√©traitement des textes (nettoyage, lemmatisation)\n",
        "- Analyse exploratoire\n",
        "- Vectorisation des textes (TF-IDF)\n",
        "- Entra√Ænement de plusieurs mod√®les de classification\n",
        "- √âvaluation comparative\n",
        "- Sauvegarde des mod√®les\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b3d8d7",
      "metadata": {
        "id": "78b3d8d7"
      },
      "source": [
        "## 1. Importation des biblioth√®ques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6be75187",
      "metadata": {
        "id": "6be75187"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd                   # manipulation de donn√©es en DataFrame\n",
        "import numpy as np                    # calculs num√©riques\n",
        "import matplotlib.pyplot as plt       # visualisation graphique\n",
        "import seaborn as sns                 # visualisation avanc√©e bas√©e sur matplotlib\n",
        "import re                             # expressions r√©guli√®res pour nettoyage texte\n",
        "import string                         # manipulation de cha√Ænes (ponctuation)\n",
        "import nltk                           # traitement de texte (stopwords)\n",
        "import joblib                         # sauvegarde et chargement de mod√®les\n",
        "import spacy                          # NLP : lemmatisation, tokenisation avanc√©e\n",
        "from wordcloud import WordCloud       # g√©n√©ration de nuage de mots\n",
        "from collections import Counter       # compter la fr√©quence des mots\n",
        "import itertools                      # op√©rations sur it√©rables\n",
        "from nltk.corpus import stopwords     # liste des mots vides (stopwords)\n",
        "\n",
        "from sklearn.model_selection import train_test_split                           # s√©paration train/test\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer   # vectorisation TF-IDF et compte\n",
        "from sklearn.linear_model import LogisticRegression                            # Logistic Regression\n",
        "from sklearn.svm import LinearSVC                                              # SVM lin√©aire\n",
        "from sklearn.ensemble import RandomForestClassifier                            # Random Forest\n",
        "from sklearn.pipeline import Pipeline                                          # pipeline de traitement\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d37facfe",
      "metadata": {
        "id": "d37facfe"
      },
      "source": [
        "## 2. Pr√©paration des outils linguistiques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "455fcec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "455fcec6",
        "outputId": "4476b70a-a2f1-4825-adbd-bbeaf456424d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "# T√©l√©chargement des stopwords fran√ßais si non d√©j√† pr√©sents\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger la liste des mots vides en fran√ßais\n",
        "stop_words = set(stopwords.words('french'))"
      ],
      "metadata": {
        "id": "n4CO0AKlU3Zu"
      },
      "id": "n4CO0AKlU3Zu",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du mod√®le SpaCy fran√ßais avec gestion d‚Äôerreur\n",
        "import subprocess\n",
        "try:\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "except:\n",
        "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"fr_core_news_sm\"])\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")"
      ],
      "metadata": {
        "id": "0QiNS7u6Ut0O"
      },
      "id": "0QiNS7u6Ut0O",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "20fdc828",
      "metadata": {
        "id": "20fdc828"
      },
      "source": [
        "## 3. Chargement du jeu de donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f6336d73",
      "metadata": {
        "id": "f6336d73"
      },
      "outputs": [],
      "source": [
        "# D√©finition des chemins vers les splits train, validation, test\n",
        "splits = {\n",
        "    'train': 'allocine/train-00000-of-00001.parquet',\n",
        "    'validation': 'allocine/validation-00000-of-00001.parquet',\n",
        "    'test': 'allocine/test-00000-of-00001.parquet'\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du fichier parquet d'entra√Ænement depuis HuggingFace datasets\n",
        "df = pd.read_parquet(\"hf://datasets/tblard/allocine/\" + splits[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqOzP-i9VHng",
        "outputId": "ed43ab65-45cc-497a-e6f6-31ed3d342dd0"
      },
      "id": "BqOzP-i9VHng",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pour acc√©l√©rer le traitement, on r√©duit √† un √©chantillon de 10 000 exemples pour limiter le temps d'ex√©cution\n",
        "df = df.sample(10000, random_state=42)\n",
        "\n",
        "# Ne garder que les colonnes utiles 'review'(texte) et 'label' (polarit√©)\n",
        "df = df[['review', 'label']]"
      ],
      "metadata": {
        "id": "kW3b0IocVYTu"
      },
      "id": "kW3b0IocVYTu",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des premi√®res lignes du DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y31FDu3VlLm",
        "outputId": "46963111-e2c1-44d0-d91f-81b1c6a9155e"
      },
      "id": "6Y31FDu3VlLm",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   review  label\n",
            "120476  Un excellent thriller d'action o√π les sc√®nes d...      1\n",
            "32693   Si le sc√©nariste, qui aurait pu faire un minim...      0\n",
            "79958   R√©f√©rence dans la filmographie de Bogart, \"Le ...      0\n",
            "76366   Un bon sc√©nario, un bon film, une histoire lou...      1\n",
            "82343   Un scenario vide et une mise en scene tr√©s sop...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "857890a5",
      "metadata": {
        "id": "857890a5"
      },
      "source": [
        "## 4. Nettoyage et lemmatisation des textes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a089ef27",
      "metadata": {
        "id": "a089ef27"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "    Cette fonction nettoie un texte brut :\n",
        "    - Passage en minuscules\n",
        "    - Suppression des chiffres\n",
        "    - Suppression de la ponctuation\n",
        "    - Lemmatisation avec SpaCy\n",
        "    - Suppression des stopwords, des tokens non alphab√©tiques et tr√®s courts (< 3 caract√®res)\n",
        "  \"\"\"\n",
        "def clean_and_lemmatize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Analyse SpaCy\n",
        "    doc = nlp(text)\n",
        "    tokens = [\n",
        "        token.lemma_ for token in doc if token.lemma_.lower() not in stop_words and token.is_alpha and len(token) > 2\n",
        "    ]\n",
        "    return \" \".join(tokens)   # reconstruire phrase nettoy√©e et lemmatis√©e\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Application de la fonction √† la colonne 'review' pour cr√©er une nouvelle colonne 'clean_review'\n",
        "df['clean_review'] = df['review'].apply(clean_and_lemmatize)"
      ],
      "metadata": {
        "id": "_Pxgs9odW4dU"
      },
      "id": "_Pxgs9odW4dU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher un aper√ßu des textes originaux et nettoy√©s\n",
        "df[['review', 'clean_review']].head()"
      ],
      "metadata": {
        "id": "bRB8JeIsW8w4"
      },
      "id": "bRB8JeIsW8w4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8f559b84",
      "metadata": {
        "id": "8f559b84"
      },
      "source": [
        "## 5. Exploration des donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa035230",
      "metadata": {
        "id": "fa035230"
      },
      "outputs": [],
      "source": [
        "# Afficher la distribution des classes (0 = n√©gatif, 1 = positif)\n",
        "print(df['label'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation graphique de la r√©partition des classes\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.title(\"Distribution des avis\")\n",
        "plt.xlabel(\"Label (0 = n√©gatif, 1 = positif)\")\n",
        "plt.ylabel(\"Nombre d'exemples\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XPWB2cDFXNaC"
      },
      "id": "XPWB2cDFXNaC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1e5ca3a0",
      "metadata": {
        "id": "1e5ca3a0"
      },
      "source": [
        "## 6. Visualisation des mots les plus fr√©quents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ee7e063",
      "metadata": {
        "id": "0ee7e063"
      },
      "outputs": [],
      "source": [
        "# Extraction de tous les mots issus de la colonne nettoy√©e\n",
        "all_words = list(itertools.chain(*df['clean_review'].str.split()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compter la fr√©quence des 20 mots les plus fr√©quents\n",
        "word_freq = Counter(all_words).most_common(20)\n",
        "words, counts = zip(*word_freq)"
      ],
      "metadata": {
        "id": "y_PRvqFgXc4H"
      },
      "id": "y_PRvqFgXc4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage sous forme de barplot\n",
        "sns.barplot(x=counts, y=words)\n",
        "plt.title(\"20 mots les plus fr√©quents\")\n",
        "plt.xlabel(\"Fr√©quence\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zJYlTuCdXiw_"
      },
      "id": "zJYlTuCdXiw_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuage de mots bas√© sur l'ensemble des mots\n",
        "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(all_words))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Nuage de mots\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cw6MN-rLXofl"
      },
      "id": "Cw6MN-rLXofl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6c940217",
      "metadata": {
        "id": "6c940217"
      },
      "source": [
        "## 7. Vectorisation des textes avec TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "296b339b",
      "metadata": {
        "id": "296b339b"
      },
      "outputs": [],
      "source": [
        "# On initialise le vectoriseur TF-IDF en limitant √† 5000 features et en incluant\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul de la matrice TF-IDF sur les textes nettoy√©s\n",
        "X = vectorizer.fit_transform(df['clean_review'])"
      ],
      "metadata": {
        "id": "jcqn2asDX3q1"
      },
      "id": "jcqn2asDX3q1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R√©cup√©ration des labels\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "U8xcfDICX8A0"
      },
      "id": "U8xcfDICX8A0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3e04e658",
      "metadata": {
        "id": "3e04e658"
      },
      "source": [
        "## 8. S√©paration des donn√©es d'entra√Ænement et de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15b12d5f",
      "metadata": {
        "id": "15b12d5f"
      },
      "outputs": [],
      "source": [
        "# 20% des donn√©es sont r√©serv√©es au test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a05770da",
      "metadata": {
        "id": "a05770da"
      },
      "source": [
        "## 9. Entra√Ænement des mod√®les de classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4b7fea",
      "metadata": {
        "id": "3d4b7fea"
      },
      "outputs": [],
      "source": [
        "# R√©gression logistique\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM lin√©aire\n",
        "svm_model = LinearSVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "_v9VMFpKYWcX"
      },
      "id": "_v9VMFpKYWcX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "53ZskssLYWJK"
      },
      "id": "53ZskssLYWJK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9752c68f",
      "metadata": {
        "id": "9752c68f"
      },
      "source": [
        "## 10. √âvaluation des mod√®les"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507145d1",
      "metadata": {
        "id": "507145d1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Cette fonction permet d'afficher la matrice de confusion, le rapport de classification et la pr√©cision globale.\n",
        "    Elle permet d'affiche aussi graphiquement la matrice de confusion.\n",
        "    \"\"\"\n",
        "def eval_model(name, y_true, y_pred):\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, display_labels=[\"N√©gatif\", \"Positif\"])\n",
        "    plt.title(f\"{name} - Matrice de confusion\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation des mod√®les\n",
        "eval_model(\"R√©gression Logistique\", y_test, y_pred_lr)\n",
        "eval_model(\"SVM Lin√©aire\", y_test, y_pred_svm)\n",
        "eval_model(\"Random Forest\", y_test, y_pred_rf)"
      ],
      "metadata": {
        "id": "X4DHBuHtYvNM"
      },
      "id": "X4DHBuHtYvNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bcb06d2a",
      "metadata": {
        "id": "bcb06d2a"
      },
      "source": [
        "### üîç F1-score pond√©r√© (compl√©ment d'√©valuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le calcul des F1-score pond√©r√©s est pr√©cieux pour mesurer la performance globale sur les classes d√©s√©quilibr√©es"
      ],
      "metadata": {
        "id": "REUqhddFZTkL"
      },
      "id": "REUqhddFZTkL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219d0259",
      "metadata": {
        "id": "219d0259"
      },
      "outputs": [],
      "source": [
        "# Calcul des F1-score pond√©r√©s\n",
        "print(\"F1-score pond√©r√© - Logistic Regression :\", f1_score(y_test, y_pred_lr, average=\"weighted\"))\n",
        "print(\"F1-score pond√©r√© - SVM :\", f1_score(y_test, y_pred_svm, average=\"weighted\"))\n",
        "print(\"F1-score pond√©r√© - Random Forest :\", f1_score(y_test, y_pred_rf, average=\"weighted\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c763887b",
      "metadata": {
        "id": "c763887b"
      },
      "source": [
        "## 11. Comparaison des performances des mod√®les (accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcf5151",
      "metadata": {
        "id": "4bcf5151"
      },
      "outputs": [],
      "source": [
        "\n",
        "models = ['Logistic Regression', 'SVM', 'Random Forest']\n",
        "accuracies = [\n",
        "    accuracy_score(y_test, y_pred_lr),\n",
        "    accuracy_score(y_test, y_pred_svm),\n",
        "    accuracy_score(y_test, y_pred_rf)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graphique de comparaison\n",
        "sns.barplot(x=models, y=accuracies)\n",
        "plt.title(\"Comparaison des pr√©cisions\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w9IWYbkWZvXG"
      },
      "id": "w9IWYbkWZvXG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "968f735f",
      "metadata": {
        "id": "968f735f"
      },
      "source": [
        "## 12. √âchantillon de pr√©dictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemple de pr√©dictions sur un petit √©chantillon pour voir les r√©sultats concrets"
      ],
      "metadata": {
        "id": "4YYV4GSSZ4kv"
      },
      "id": "4YYV4GSSZ4kv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0f150a2",
      "metadata": {
        "id": "c0f150a2"
      },
      "outputs": [],
      "source": [
        "# Test sur un √©chantillon (y_test)\n",
        "indices = y_test.iloc[:5].index\n",
        "sample_preds = pd.DataFrame({\n",
        "    \"Review\": df.loc[indices, 'review'].values,\n",
        "    \"Label r√©el\": y_test.loc[indices].values,\n",
        "    \"Pr√©diction LR\": y_pred_lr[:5],\n",
        "    \"Pr√©diction SVM\": y_pred_svm[:5],\n",
        "    \"Pr√©diction RF\": y_pred_rf[:5]\n",
        "})\n",
        "sample_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "497d8ca1",
      "metadata": {
        "id": "497d8ca1"
      },
      "source": [
        "## 13. Sauvegarde des mod√®les entra√Æn√©s pour r√©utilisation future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112610cd",
      "metadata": {
        "id": "112610cd"
      },
      "outputs": [],
      "source": [
        "\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")    # vectoriseur TF-IDF\n",
        "joblib.dump(lr_model, \"logistic_model.pkl\")        # mod√®le Logistic Regression\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")            # mod√®le SVM\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")   # mod√®le Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©ation d'un pipeline complet avec vectorisation + mod√®le LR pour simplifier la pr√©diction ult√©rieure\n",
        "pipeline_lr = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2))),\n",
        "    ('clf', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "pipeline_lr.fit(df['clean_review'], df['label'])\n",
        "joblib.dump(pipeline_lr, \"pipeline_logistic.pkl\")\n",
        "\n",
        "print(\"Tous les mod√®les ont √©t√© sauvegard√©s avec succ√®s.\")\n"
      ],
      "metadata": {
        "id": "cbXzjFCRaZ2m"
      },
      "id": "cbXzjFCRaZ2m",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}